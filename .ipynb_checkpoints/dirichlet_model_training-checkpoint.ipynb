{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dirichlet model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will train Dirichlet model for atrial fibrillation detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Dataset initialization](#Dataset-initialization)\n",
    "* [Training pipeline](#Training-pipeline)\n",
    "* [Saving the model](#Saving-the-model)\n",
    "* [Testing pipeline](#Testing-pipeline)\n",
    "* [Predicting pipeline](#Predicting-pipeline)\n",
    "* [Analyzing the uncertainty](#Analyzing-the-uncertainty)\n",
    "* [Visualizing predictions](#Visualizing-predictions)\n",
    "    * [Certain prediction](#Certain-prediction)\n",
    "    * [Uncertain prediction](#Uncertain-prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/dicom/__init__.py:53: UserWarning: \n",
      "This code is using an older version of pydicom, which is no longer \n",
      "maintained as of Jan 2017.  You can access the new pydicom features and API \n",
      "by installing `pydicom` from PyPI.\n",
      "See 'Transitioning to pydicom 1.x' section at pydicom.readthedocs.org \n",
      "for more information.\n",
      "\n",
      "  warnings.warn(msg)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import beta\n",
    "\n",
    "sys.path.append(os.path.join(\"..\", \"..\", \"..\"))\n",
    "import cardio.dataset as ds\n",
    "from cardio import EcgDataset\n",
    "from cardio.dataset import B, V, F\n",
    "from cardio.models.dirichlet_model import DirichletModel, concatenate_ecg_batch\n",
    "from cardio.models.metrics import f1_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn plotting parameters setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(\"talk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, TensorFlow attempts to allocate almost the entire memory on all of the available GPUs. Executing this instruction makes only the GPU with id 0 visible for TensorFlow in this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "#%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to specify paths to ECG signals and their labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGNALS_PATH = os.path.expanduser(\"~\")+\"/coding/cnn/datasets/training2017/\"\n",
    "SIGNALS_MASK = SIGNALS_PATH + \"*.hea\"\n",
    "LABELS_PATH = SIGNALS_PATH + \"REFERENCE.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create an ECG dataset and perform a train/test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eds = EcgDataset(path=SIGNALS_MASK, no_ext=True, sort=True)\n",
    "eds.cv_split(0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dirichlet model builder expects model config to contain input signals' shape and class names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5, allow_growth=True)\n",
    "\n",
    "model_config = {\n",
    "    \"session\": {\"config\": tf.ConfigProto(gpu_options=gpu_options)},\n",
    "    \"input_shape\": F(lambda batch: batch.signal[0].shape[1:]),\n",
    "    \"class_names\": F(lambda batch: batch.label_binarizer.classes_),\n",
    "    \"loss\": None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCH = 1000\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training pipeline is composed of:\n",
    "* model initialization with the config defined above\n",
    "* data loading, preprocessing (e.g. flipping) and augmentation (e.g. resampling)\n",
    "* train step execution\n",
    "\n",
    "Let's create a template pipeline, then link it to our training dataset and run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_train_ppl = (\n",
    "    ds.Pipeline()\n",
    "      .init_model(\"dynamic\", DirichletModel, name=\"dirichlet\", config=model_config)\n",
    "      .init_variable(\"loss_history\", init_on_each_run=list)\n",
    "      .load(components=[\"signal\", \"meta\"], fmt=\"wfdb\")\n",
    "      .load(components=\"target\", fmt=\"csv\", src=LABELS_PATH)\n",
    "      .drop_labels([\"~\"])\n",
    "      .rename_labels({\"N\": \"NO\", \"O\": \"NO\"})\n",
    "      .flip_signals()\n",
    "      .random_resample_signals(\"normal\", loc=300, scale=10)\n",
    "      .random_split_signals(2048, {\"A\": 9, \"NO\": 3})\n",
    "      .binarize_labels()\n",
    "      .train_model(\"dirichlet\", make_data=concatenate_ecg_batch,\n",
    "                   fetches=\"loss\", save_to=V(\"loss_history\"), mode=\"a\")\n",
    "      .run(batch_size=BATCH_SIZE, shuffle=True, drop_last=True, n_epochs=N_EPOCH, lazy=True)\n",
    ")\n",
    "\n",
    "train_ppl = (eds.train >> template_train_ppl).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loss is stored in \"loss_history\" pipeline variable. Let's take a look at its plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = [np.mean(l) for l in np.array_split(train_ppl.get_variable(\"loss_history\"), N_EPOCH)]\n",
    "\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "plt.plot(train_loss)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Training loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, training loss almost reaches a plateau by the end of the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL_PATH = \"D:\\\\Projects\\\\data\\\\ecg\\\\dirichlet_model\"\n",
    "MODEL_PATH = os.path.expanduser(\"~\")+\"/coding/cnn/DeepECG/dirichlet_model\"\n",
    "train_ppl.save_model(\"dirichlet\", path=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing pipeline is almost identical to the training one. The differences lie in the absence of signal resampling and the modified segmentation procedure. Notice, that the model is imported from the training pipeline, rather than being constructed from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_test_ppl = (\n",
    "    ds.Pipeline()\n",
    "      .import_model(\"dirichlet\", train_ppl)\n",
    "      .init_variable(\"predictions_list\", init_on_each_run=list)\n",
    "      .load(components=[\"signal\", \"meta\"], fmt=\"wfdb\")\n",
    "      .load(components=\"target\", fmt=\"csv\", src=LABELS_PATH)\n",
    "      .drop_labels([\"~\"])\n",
    "      .rename_labels({\"N\": \"NO\", \"O\": \"NO\"})\n",
    "      .flip_signals()\n",
    "      .split_signals(2048, 2048)\n",
    "      .binarize_labels()\n",
    "      .predict_model(\"dirichlet\", make_data=concatenate_ecg_batch,\n",
    "                     fetches=\"predictions\", save_to=V(\"predictions_list\"), mode=\"e\")\n",
    "      .run(batch_size=BATCH_SIZE, shuffle=False, drop_last=False, n_epochs=1, lazy=True)\n",
    ")\n",
    "\n",
    "test_ppl = (eds.test >> template_test_ppl).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now \"predictions_list\" pipeline variable stores model predictions and true targets for all signals labeled with \"A\", \"O\" and \"N\" in the testing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use [F1-score](https://en.wikipedia.org/wiki/F1_score) with macro averaging to measure classification performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = test_ppl.get_variable(\"predictions_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also take a look at the more detailed report - the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model misclassifies 33 patients with atrial fibrillation and 25 patients with normal and other rhythms. All other patients were classified correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve already obtained good classification performance. Let’s see if we can do even better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to class probabilities the model returns its uncertainty in the prediction, which varies from 0 (absolutely sure) to 1 (absolutely unsure). You can see the uncertainty histogram on the plot below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty = [d[\"uncertainty\"] for d in predictions]\n",
    "\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "sns.distplot(uncertainty, hist=True, norm_hist=True, kde=False)\n",
    "plt.xlabel(\"Model uncertainty\")\n",
    "plt.xlim(-0.05, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure above shows, that the model is almost always certain in its predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the metrics for the full testing dataset above with the same metrics for 90% most certain predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 90\n",
    "thr = np.percentile(uncertainty, q)\n",
    "certain_predictions = [d for d in predictions if d[\"uncertainty\"] <= thr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(certain_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(certain_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(certain_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe a significant increase in precision, recall and F1-score for the atrial fibrillation class. Now only 16 signals were misclassified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's predict class probabilities for a new, unobserved ECG signal.<br>\n",
    "Besides, we will load pretrained model from MODEL_PATH directory instead of importing it from another pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIGNALS_PATH = \"D:\\\\Projects\\\\data\\\\ecg\\\\training2017\\\\\"\n",
    "SIGNALS_PATH = os.path.expanduser(\"~\")+\"/coding/cnn/datasets/training2017/\"\n",
    "# MODEL_PATH = \"D:\\\\Projects\\\\data\\\\ecg\\\\dirichlet_model\"\n",
    "MODEL_PATH = os.path.expanduser(\"~\")+\"/coding/cnn/DeepECG/dirichlet_model\"\n",
    "\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5, allow_growth=True)\n",
    "\n",
    "model_config = {\n",
    "    \"session\": {\"config\": tf.ConfigProto(gpu_options=gpu_options)},\n",
    "    \"build\": False,\n",
    "    \"load\": {\"path\": MODEL_PATH},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_predict_ppl = (\n",
    "    ds.Pipeline()\n",
    "      .init_model(\"static\", DirichletModel, name=\"dirichlet\", config=model_config)\n",
    "      .init_variable(\"predictions_list\", init_on_each_run=list)\n",
    "      .load(fmt=\"wfdb\", components=[\"signal\", \"meta\"])\n",
    "      .flip_signals()\n",
    "      .split_signals(2048, 2048)\n",
    "      .predict_model(\"dirichlet\", make_data=partial(concatenate_ecg_batch, return_targets=False),\n",
    "                     fetches=\"predictions\", save_to=V(\"predictions_list\"), mode=\"e\")\n",
    "      .run(batch_size=BATCH_SIZE, shuffle=False, drop_last=False, n_epochs=1, lazy=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a dataset with a single ECG in it, then link it to the template predicting pipeline defined above and run it. Model prediction will be stored in the \"predictions_list\" variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_name = \"A00001.hea\"\n",
    "signal_path = SIGNALS_PATH + signal_name\n",
    "predict_eds = EcgDataset(path=signal_path, no_ext=True, sort=True)\n",
    "predict_ppl = (predict_eds >> template_predict_ppl).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_ppl.get_variable(\"predictions_list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The length of the resulting list equals the length of the index of the dataset (1 in out case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the target Dirichlet mixture density for a given signal. The pipeline below stores the signal and Dirichlet distribution parameters in its variables in addition to the predicted class probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_full_predict_ppl = (\n",
    "    ds.Pipeline()\n",
    "      .init_model(\"static\", DirichletModel, name=\"dirichlet\", config=model_config)\n",
    "      .init_variable(\"signals\", init_on_each_run=list)\n",
    "      .init_variable(\"predictions_list\", init_on_each_run=list)\n",
    "      .init_variable(\"parameters_list\", init_on_each_run=list)\n",
    "      .load(fmt=\"wfdb\", components=[\"signal\", \"meta\"])\n",
    "      .update_variable(\"signals\", value=B(\"signal\"))\n",
    "      .flip_signals()\n",
    "      .split_signals(2048, 2048)\n",
    "      .predict_model(\"dirichlet\", make_data=partial(concatenate_ecg_batch, return_targets=False),\n",
    "                     fetches=[\"predictions\", \"parameters\"],\n",
    "                     save_to=[V(\"predictions_list\"), V(\"parameters_list\")], mode=\"e\")\n",
    "      .run(batch_size=BATCH_SIZE, shuffle=False, drop_last=False, n_epochs=1, lazy=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_visualize(signal_path):\n",
    "    predict_eds = EcgDataset(path=signal_path, no_ext=True, sort=True)\n",
    "    \n",
    "    full_predict_ppl = (predict_eds >> template_full_predict_ppl).run()\n",
    "    signal = full_predict_ppl.get_variable(\"signals\")[0][0][0][:2000].ravel()\n",
    "    predictions = full_predict_ppl.get_variable(\"predictions_list\")[0]\n",
    "    parameters = full_predict_ppl.get_variable(\"parameters_list\")[0]\n",
    "    \n",
    "    print(predictions)\n",
    "\n",
    "    x = np.linspace(0.001, 0.999, 1000)\n",
    "    y = np.zeros_like(x)\n",
    "    for alpha in parameters:\n",
    "        y += beta.pdf(x, *alpha)\n",
    "    y /= len(parameters)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, gridspec_kw={\"width_ratios\": [2.5, 1]}, figsize=(15, 4))\n",
    "\n",
    "    ax1.plot(signal)\n",
    "\n",
    "    ax2.plot(x, y)\n",
    "    ax2.fill_between(x, y, alpha=0.3)\n",
    "    ax2.set_ylim(ymin=0)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Certain prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let’s look at the healthy person’s ECG. The signal is shown on the left plot. Note that it has a clear quasi periodic structure. The right plot shows the pdf of the mixture distributions with atrial fibrillation probability plotted on the horizontal axis. The model is absolutely certain in the absence of AF: almost all the probability density is concentrated around 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_and_visualize(SIGNALS_PATH + \"A00150.hea\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertain prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now comes an ECG with irregular structure, which may be caused by a disease or some measurement errors. The probability density on the right plot is almost equally concentrated around 0 and 1. This is an example of an uncertain prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_and_visualize(SIGNALS_PATH + \"A01505.hea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
